{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mromano/opt/anaconda3/envs/unet_prax-env/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "from typing import List\n",
    "from torchvision import io\n",
    "from torchvision import transforms\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLayer(nn.Module):\n",
    "    def __init__(self, inchannels, upsamp_multiplier):\n",
    "        super(ConvLayer, self).__init__()\n",
    "        outchannels = int(inchannels*upsamp_multiplier)\n",
    "        self._conv1 = nn.Conv2d(\n",
    "            inchannels, \n",
    "            outchannels,\n",
    "            kernel_size=3)\n",
    "        self._conv2 = nn.Conv2d(\n",
    "            outchannels,\n",
    "            outchannels,\n",
    "            kernel_size=3\n",
    "            )\n",
    "        self.net = nn.Sequential(\n",
    "            self._conv1, \n",
    "            nn.ReLU(),\n",
    "            self._conv2,\n",
    "            nn.ReLU())\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, inchannels: int=1):\n",
    "        super(UNet, self).__init__()\n",
    "        self.conv1 = ConvLayer(inchannels, 64)\n",
    "        self.pool1 = nn.MaxPool2d((2,2), 2)\n",
    "        self.conv2 = ConvLayer(inchannels*64, 2)\n",
    "        self.pool2 = nn.MaxPool2d((2,2), 2)\n",
    "        self.conv3 = ConvLayer(inchannels*64*2, 2)\n",
    "        self.pool3 = nn.MaxPool2d((2,2), 2)\n",
    "        self.conv4 = ConvLayer(inchannels*64*4, 2)\n",
    "        self.pool4 = nn.MaxPool2d((2,2), 2)\n",
    "        self.conv5 = ConvLayer(inchannels*64*8, 2)        \n",
    "\n",
    "        self.deconv1 = nn.ConvTranspose2d(inchannels*16*64, inchannels*8*64, (2,2),2)\n",
    "        self.conv6 = ConvLayer(inchannels*16*64, 0.5)\n",
    "        self.deconv2 = nn.ConvTranspose2d(inchannels*8*64, inchannels*4*64, (2,2),2)\n",
    "        self.conv7 = ConvLayer(inchannels*8*64, 0.5)\n",
    "        self.deconv3 = nn.ConvTranspose2d(inchannels*4*64, inchannels*2*64, (2,2),2)\n",
    "        self.conv8 = ConvLayer(inchannels*4*64, 0.5)\n",
    "        self.deconv4 = nn.ConvTranspose2d(inchannels*2*64, inchannels*64, (2,2),2)\n",
    "        self.conv9 = ConvLayer(inchannels*2*64, 0.5)\n",
    "        self.conv10 = nn.Conv2d(inchannels*64, 2, (1,1), 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.conv1(x)\n",
    "        x2 = self.conv2(self.pool1(x1))\n",
    "        x3 = self.conv3(self.pool2(x2))\n",
    "        x4 = self.conv4(self.pool3(x3))\n",
    "        x5 = self.conv5(self.pool4(x4))\n",
    "        print(x5.shape)\n",
    "        \n",
    "        x_up_1 = self.deconv1(x5)\n",
    "        x_up_1 = torch.concat((\n",
    "            transforms.CenterCrop(x_up_1.shape[2:3])(x4),\n",
    "            x_up_1), axis=1)\n",
    "        print(x_up_1.shape)\n",
    "\n",
    "        x_up_2 = self.deconv2(self.conv6(x_up_1))\n",
    "        x_up_2 = torch.concat(\n",
    "            (transforms.CenterCrop(x_up_2.shape[2:3])(x3),\n",
    "            x_up_2), dim=1)\n",
    "        print(x_up_2.shape)\n",
    "\n",
    "        x_up_3 = self.deconv3(self.conv7(x_up_2))\n",
    "        x_up_3 = torch.concat(\n",
    "            (transforms.CenterCrop(x_up_3.shape[2:3])(x2),\n",
    "            x_up_3), dim=1)\n",
    "        print(x_up_3.shape)\n",
    "\n",
    "        x_up_4 = self.deconv4(self.conv8(x_up_3))\n",
    "        x_up_4 = torch.concat(\n",
    "            (transforms.CenterCrop(x_up_4.shape[2:3])(x1),\n",
    "            x_up_4), dim=1)\n",
    "        print(x_up_4.shape)\n",
    "        xout = self.conv10(self.conv9(x_up_4))\n",
    "        return xout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 1024, 1024])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the output shape of UNet\n",
    "test_im = io.read_image('../xray_samp/sample/images/00000013_005.png')\n",
    "test_im = test_im.float().unsqueeze(0)\n",
    "test_im.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1024, 56, 56])\n",
      "torch.Size([1, 1024, 112, 112])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given transposed=1, weight of size [512, 256, 2, 2], expected input[1, 1024, 112, 112] to have 512 channels, but got 1024 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/w5/2v0w9g6936v76hvg244v5gxw0000gp/T/ipykernel_24254/4089748225.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_im\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/unet_prax-env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/w5/2v0w9g6936v76hvg244v5gxw0000gp/T/ipykernel_24254/65224941.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_up_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0mx_up_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_up_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         x_up_2 = torch.concat(\n\u001b[1;32m     62\u001b[0m             (transforms.CenterCrop(x_up_2.shape[2:3])(x3),\n",
      "\u001b[0;32m~/opt/anaconda3/envs/unet_prax-env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/unet_prax-env/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, output_size)\u001b[0m\n\u001b[1;32m    950\u001b[0m         return F.conv_transpose2d(\n\u001b[1;32m    951\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m             output_padding, self.groups, self.dilation)\n\u001b[0m\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given transposed=1, weight of size [512, 256, 2, 2], expected input[1, 1024, 112, 112] to have 512 channels, but got 1024 channels instead"
     ]
    }
   ],
   "source": [
    "net = UNet(1)\n",
    "out = net(test_im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Initialize network weights as follows : √2/N, where N denotes the number of incoming nodes of one neuron [5]. E.g. for a 3x3 convolution and 64 feature channels in the previous layerN= 9·64 = 576\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('unet_prax-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bba0aa6026272d72fa4312733ee44244b566d0cb10b9a208c00528c53cf61bbc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
